---
name: dev-containers
description: Set up local development environments with production parity for DigitalOcean App Platform
version: 1.0.0
author: Bikram Gupta
triggers:
  - "local dev"
  - "devcontainer"
  - "docker compose"
  - "run locally"
  - "development environment"
  - "set up local"
config:
  DEVCONTAINER_REPO_URL: https://github.com/bikramkgupta/do-app-devcontainer
  DEVCONTAINER_REPO_BRANCH: main
---

# Dev Containers Skill

## Overview

Set up local development environments with production parity for DigitalOcean App Platform applications. This skill eliminates "works on my machine" problems by providing containerized development with the same databases, queues, and storage you'll use in production.

**Primary value**: 30-second feedback loops instead of 7-minute deploy cycles.

**What this skill produces:**
- `.devcontainer/devcontainer.json` — IDE configuration (VS Code, Cursor, Claude Code)
- `.devcontainer/docker-compose.yml` — All backing services
- `.env.example` or `env-devcontainer.example` — Environment template

**When to use this skill:**
- "Help me run this locally"
- "Set up local dev environment"
- "I need Postgres and Redis for development"
- "Add devcontainer to my project"

**When NOT to use this skill:**
- Deploying to production → use **deployment** skill
- Debugging production issues → use **troubleshooting** skill  
- Testing in cloud without rebuild → use **hot-reload** skill

---

## Quick Start

### Source of Truth

The canonical devcontainer configuration lives at:
**`${DEVCONTAINER_REPO_URL}`** (default: https://github.com/bikramkgupta/do-app-devcontainer)

All templates, test scripts, and docker-compose configurations should be sourced from this repo. The skill provides instructions on how to use them, not duplicate copies.

### Fastest Path: Clone and Copy

```bash
# Clone the reference devcontainer (replace URL if using a fork)
git clone --depth 1 ${DEVCONTAINER_REPO_URL}.git /tmp/devcontainer-ref

# Copy to your project
cp -r /tmp/devcontainer-ref/.devcontainer /path/to/your-project/

# Clean up
rm -rf /tmp/devcontainer-ref
```

Then customize `COMPOSE_PROFILES` in `.devcontainer/devcontainer.json`:
```json
"containerEnv": {
  "COMPOSE_PROFILES": "app,postgres,minio"  // Add what you need
}
```

**Available profiles:** `postgres`, `mongo`, `mysql`, `valkey`, `kafka`, `minio`, `opensearch`

### What You Get from the Repo

```
.devcontainer/
├── devcontainer.json           # IDE configuration
├── docker-compose.yml          # All 7 backing services
├── init.sh                     # Git worktree support
├── post-create.sh              # Post-creation setup
├── .env                        # Generated by init.sh (gitignored)
├── docs/                       # Additional documentation
│   └── worktree-setup.md
├── images/                     # Architecture diagrams
└── tests/                      # Service connectivity tests
    ├── agent-test.sh           # E2E validation for agents
    ├── run-all-tests.sh        # Master test runner
    ├── common.sh               # Shared helpers
    ├── test-postgres.sh
    ├── test-mysql.sh
    ├── test-mongo.sh
    ├── test-valkey.sh
    ├── test-kafka.sh
    ├── test-opensearch.sh
    └── test-rustfs.sh
```

---

## Workflows

### Workflow 1: New Project Setup

**Trigger:** "I'm building a [language] app with [services]"

**Steps:**

1. **Detect or ask for requirements:**
   - Language/framework (Node.js, Python, Go, etc.)
   - Required services (Postgres, Redis, Kafka, etc.)
   - S3-compatible storage needed?

2. **Generate `.devcontainer/devcontainer.json`:**

```json
{
  "name": "App Platform Dev Environment",
  "dockerComposeFile": "docker-compose.yml",
  "service": "app",
  "workspaceFolder": "/workspaces/app",
  "features": {
    "ghcr.io/devcontainers/features/github-cli:1": {},
    "ghcr.io/devcontainers/features/node:1": {},
    "ghcr.io/devcontainers/features/python:1": {},
    "ghcr.io/devcontainers-extra/features/uv:1": {},
    "ghcr.io/devcontainers-extra/features/digitalocean-cli:1": {},
    "ghcr.io/devcontainers/features/aws-cli:1": {},
    "ghcr.io/anthropics/devcontainer-features/claude-code:1": {},
    "ghcr.io/devcontainers/features/docker-outside-of-docker:1": {
      "moby": false,
      "dockerDashComposeVersion": "v2"
    }
  },
  "containerEnv": {
    "COMPOSE_PROFILES": "app,postgres"
  },
  "initializeCommand": "cd \"${localWorkspaceFolder}\" && bash .devcontainer/init.sh",
  "postCreateCommand": ".devcontainer/post-create.sh",
  "remoteUser": "vscode",
  "shutdownAction": "stopCompose",
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-azuretools.vscode-docker"
      ]
    }
  }
}
```

3. **Generate `docker-compose.yml`** with only the services needed (see Service Templates below)

4. **Generate environment template** (`env-devcontainer.example`):

```bash
# Database - use service name, not localhost
DATABASE_URL=postgresql://postgres:password@postgres:5432/app

# Add other services as needed
```

5. **Provide startup instructions:**

```
To start development:
1. Open this folder in VS Code or Cursor
2. When prompted, click "Reopen in Container"
3. Wait for the container to build (first time takes 2-3 minutes)
4. Your terminal is now inside the dev container with all services running
```

---

### Workflow 2: Add Local Dev to Existing App Platform App

**Trigger:** "I have an App Platform app, help me run it locally"

**Steps:**

1. **Read existing app spec** (`.do/app.yaml` or `app-spec.yaml`):

```yaml
# Example app spec to parse
services:
  - name: api
    github:
      repo: user/repo
      branch: main
    envs:
      - key: DATABASE_URL
        scope: RUN_TIME
        value: ${db.DATABASE_URL}
      - key: REDIS_URL
        scope: RUN_TIME
        value: ${redis.REDIS_URL}
databases:
  - name: db
    engine: PG
    version: "15"
```

2. **Map App Platform services to local equivalents:**

| App Platform | Local Container | Profile |
|--------------|-----------------|---------|
| `databases[].engine: PG` | `postgres:18` | `postgres` |
| `databases[].engine: MYSQL` | `mysql:8` | `mysql` |
| `databases[].engine: MONGODB` | `mongo:8` | `mongo` |
| `databases[].engine: REDIS` | `valkey/valkey:8` | `valkey` |
| Spaces attachment | `rustfs/rustfs:latest` | `minio` |
| (future) Kafka managed | `confluentinc/cp-kafka:7.7.0` | `kafka` |

3. **Generate compose profiles** based on detected services:

```json
"COMPOSE_PROFILES": "app,postgres,valkey"
```

4. **Generate environment mapping:**

```bash
# Production (App Platform injects these)
# DATABASE_URL=${db.DATABASE_URL}

# Local Development
DATABASE_URL=postgresql://postgres:password@postgres:5432/app
REDIS_URL=redis://valkey:6379
```

---

### Workflow 3: Complex Multi-Service Setup

**Trigger:** "I need Postgres, Kafka, OpenSearch, and S3 storage locally"

**Steps:**

1. **Set all required profiles:**

```json
"COMPOSE_PROFILES": "app,postgres,kafka,opensearch,minio"
```

2. **Generate complete docker-compose.yml** (use full template below)

3. **Provide service-specific connection info:**

```bash
# Databases
DATABASE_URL=postgresql://postgres:password@postgres:5432/app

# Message Queue
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# Search
OPENSEARCH_URL=http://opensearch:9200

# S3-compatible Storage (RustFS)
SPACES_ENDPOINT=http://minio:9000
SPACES_KEY_ID=rustfsadmin
SPACES_SECRET_KEY=rustfsadmin
SPACES_BUCKET_NAME=my-app-local
SPACES_FORCE_PATH_STYLE=true
```

4. **Note health check ordering:**
   - Kafka takes 60s+ to start (KRaft initialization)
   - OpenSearch takes 30-60s
   - Other services are ready in <10s

---

## Service Templates

### Base docker-compose.yml Structure

```yaml
services:
  app:
    image: mcr.microsoft.com/devcontainers/base:noble
    profiles: [ "app" ]
    volumes:
      - ..:/workspaces/app:cached
      - ${GIT_COMMON_DIR}:${GIT_COMMON_DIR}:cached
      - app-config:/home/vscode/.config
      - claude-config:/home/vscode/.claude
    command: sleep infinity
    networks:
      - devcontainer-network

  # Add service blocks below based on requirements

volumes:
  app-config:
  claude-config:
  # Add service-specific volumes

networks:
  devcontainer-network:
    driver: bridge
```

### PostgreSQL

```yaml
postgres:
  image: postgres:18
  profiles: [ "postgres" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:5432"
  environment:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: password
    POSTGRES_DB: app
  volumes:
    - postgres-data:/var/lib/postgresql
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD-SHELL", "pg_isready -U postgres"]
    interval: 10s
    timeout: 5s
    retries: 5
```

**Connection string:** `postgresql://postgres:password@postgres:5432/app`

### MySQL

```yaml
mysql:
  image: mysql:8
  profiles: [ "mysql" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:3306"
  environment:
    MYSQL_ROOT_PASSWORD: password
    MYSQL_DATABASE: app
    MYSQL_USER: mysql
    MYSQL_PASSWORD: mysql
  volumes:
    - mysql-data:/var/lib/mysql
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-ppassword"]
    interval: 10s
    timeout: 5s
    retries: 5
```

**Connection string:** `mysql://mysql:mysql@mysql:3306/app`

### MongoDB

```yaml
mongo:
  image: mongo:8
  profiles: [ "mongo" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:27017"
  environment:
    MONGO_INITDB_ROOT_USERNAME: mongodb
    MONGO_INITDB_ROOT_PASSWORD: mongodb
    MONGO_INITDB_DATABASE: app
  volumes:
    - mongo-data:/data/db
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
    interval: 10s
    timeout: 5s
    retries: 5
```

**Connection string:** `mongodb://mongodb:mongodb@mongo:27017/app?authSource=admin`

### Valkey (Redis-compatible)

```yaml
valkey:
  image: valkey/valkey:8
  profiles: [ "valkey" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:6379"
  volumes:
    - valkey-data:/data
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD", "valkey-cli", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5
```

**Connection string:** `redis://valkey:6379`

### Kafka (KRaft mode - no Zookeeper)

```yaml
kafka:
  image: confluentinc/cp-kafka:7.7.0
  profiles: [ "kafka" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:9092"
  environment:
    KAFKA_NODE_ID: 1
    CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    KAFKA_PROCESS_ROLES: broker,controller
    KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    KAFKA_NUM_PARTITIONS: 1
  volumes:
    - kafka-data:/var/lib/kafka/data
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s
```

**Bootstrap servers:** `kafka:9092`

### RustFS (S3-compatible Storage)

```yaml
# Profile name "minio" kept for backward compatibility
minio:
  image: rustfs/rustfs:latest
  profiles: [ "minio" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:9000"  # API (S3-compatible)
    - "127.0.0.1:0:9001"  # Console
  volumes:
    - minio-data:/data
    - minio-logs:/logs
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD", "curl", "-sf", "http://localhost:9000/health"]
    interval: 30s
    timeout: 20s
    retries: 3
```

**Credentials:** `rustfsadmin` / `rustfsadmin`
**Endpoint:** `http://minio:9000`

### OpenSearch

```yaml
opensearch:
  image: opensearchproject/opensearch:3.0.0
  profiles: [ "opensearch" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:9200"
    - "127.0.0.1:0:9300"
  environment:
    - discovery.type=single-node
    - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
    - "DISABLE_INSTALL_DEMO_CONFIG=true"
    - "DISABLE_SECURITY_PLUGIN=true"
  volumes:
    - opensearch-data:/usr/share/opensearch/data
  networks:
    - devcontainer-network
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s

opensearch-dashboards:
  image: opensearchproject/opensearch-dashboards:3.0.0
  profiles: [ "opensearch" ]
  restart: unless-stopped
  ports:
    - "127.0.0.1:0:5601"
  environment:
    - "OPENSEARCH_HOSTS=http://opensearch:9200"
    - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true"
  depends_on:
    opensearch:
      condition: service_healthy
  networks:
    - devcontainer-network
```

**Endpoint:** `http://opensearch:9200`

---

## Language Configurations

### Enabling Languages in devcontainer.json

```json
"features": {
  // Always enabled (needed for tooling)
  "ghcr.io/devcontainers/features/node:1": {},
  "ghcr.io/devcontainers/features/python:1": {},
  
  // Uncomment as needed
  // "ghcr.io/devcontainers/features/go:1": {},
  // "ghcr.io/devcontainers/features/rust:1": {},
  // "ghcr.io/devcontainers/features/ruby:1": {},
  // "ghcr.io/devcontainers/features/php:1": {},
}
```

### Hot Reload Configuration by Language

#### Node.js (nodemon or tsx)

**package.json:**
```json
{
  "scripts": {
    "dev": "nodemon src/index.js",
    "dev:ts": "tsx watch src/index.ts"
  },
  "devDependencies": {
    "nodemon": "^3.0.0",
    "tsx": "^4.0.0"
  }
}
```

#### Python (uvicorn or Flask)

**FastAPI:**
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Flask:**
```bash
flask run --debug --host 0.0.0.0 --port 5000
```

#### Go (air)

**.air.toml:**
```toml
root = "."
tmp_dir = "tmp"

[build]
cmd = "go build -o ./tmp/main ."
bin = "tmp/main"
include_ext = ["go", "tpl", "tmpl", "html"]
exclude_dir = ["tmp", "vendor"]
```

---

## S3-Compatible Storage (Local vs Production)

### The Problem

DigitalOcean Spaces and local S3 storage (RustFS/MinIO) require different configurations:

| Aspect | Local (RustFS) | Production (DO Spaces) |
|--------|----------------|------------------------|
| Endpoint | `http://minio:9000` | `https://{region}.digitaloceanspaces.com` |
| Path Style | `true` (required) | `false` |
| Bucket Creation | Auto-create on connect | Manual via dashboard/CLI |
| Credentials | `rustfsadmin/rustfsadmin` | Your Spaces access keys |

### Environment Variable Pattern

**Local Development (`env-devcontainer`):**
```bash
SPACES_ENDPOINT=http://minio:9000
SPACES_KEY_ID=rustfsadmin
SPACES_SECRET_KEY=rustfsadmin
SPACES_BUCKET_NAME=my-app-local
SPACES_FORCE_PATH_STYLE=true
SPACES_REGION=us-east-1
```

**Production (App Platform env vars):**
```bash
SPACES_KEY_ID=DO00...
SPACES_SECRET_KEY=...
SPACES_BUCKET_NAME=my-app-prod
SPACES_REGION=nyc3
# SPACES_ENDPOINT not set - uses default DO Spaces URL
```

### Code Pattern: Auto-Detect Local Endpoint

```typescript
// TypeScript/JavaScript
function isLocalS3Endpoint(): boolean {
  const endpoint = process.env.SPACES_ENDPOINT || '';
  return (
    endpoint.startsWith('http://') ||
    endpoint.includes('localhost') ||
    endpoint.includes('minio') ||
    endpoint.includes('127.0.0.1')
  );
}

// S3 Client configuration
const s3Client = new S3Client({
  endpoint: process.env.SPACES_ENDPOINT || 
    `https://${process.env.SPACES_REGION}.digitaloceanspaces.com`,
  region: process.env.SPACES_REGION || 'us-east-1',
  forcePathStyle: isLocalS3Endpoint(),
  credentials: {
    accessKeyId: process.env.SPACES_KEY_ID!,
    secretAccessKey: process.env.SPACES_SECRET_KEY!,
  },
});
```

```python
# Python
import os
from boto3 import client

def is_local_s3_endpoint():
    endpoint = os.environ.get('SPACES_ENDPOINT', '')
    return any(x in endpoint for x in ['http://', 'localhost', 'minio', '127.0.0.1'])

s3 = client(
    's3',
    endpoint_url=os.environ.get('SPACES_ENDPOINT') or 
        f"https://{os.environ['SPACES_REGION']}.digitaloceanspaces.com",
    aws_access_key_id=os.environ['SPACES_KEY_ID'],
    aws_secret_access_key=os.environ['SPACES_SECRET_KEY'],
    config=Config(s3={'addressing_style': 'path' if is_local_s3_endpoint() else 'virtual'})
)
```

### Auto-Create Bucket (Local Only)

For local development, auto-create the bucket if it doesn't exist:

```typescript
async function ensureBucketExists(client: S3Client, bucket: string) {
  if (!isLocalS3Endpoint()) return; // Only for local
  
  try {
    await client.send(new HeadBucketCommand({ Bucket: bucket }));
  } catch (error: any) {
    if (error.name === 'NotFound' || error.name === 'NoSuchBucket') {
      await client.send(new CreateBucketCommand({ Bucket: bucket }));
      console.log(`Created bucket: ${bucket}`);
    }
  }
}
```

---

## Helper Scripts

### init.sh (Git Worktree Support)

```bash
#!/bin/bash
# Git worktree support for devcontainers
gitdir="$(git rev-parse --git-common-dir)"
case $gitdir in
    /*) ;;
    *) gitdir="$PWD/$gitdir"
esac

project_name="$(basename "$PWD")"

sed -i.bak '/^GIT_COMMON_DIR=/d' ".devcontainer/.env" 2>/dev/null || true
sed -i.bak '/^COMPOSE_PROJECT_NAME=/d' ".devcontainer/.env" 2>/dev/null || true
rm -f ".devcontainer/.env.bak" 2>/dev/null || true

[ -n "$(tail -c 1 ".devcontainer/.env" 2>/dev/null)" ] && echo "" >> ".devcontainer/.env"

echo "COMPOSE_PROJECT_NAME=$project_name" >> ".devcontainer/.env"
echo "GIT_COMMON_DIR=$gitdir" >> ".devcontainer/.env"
```

### post-create.sh

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "DevContainer Post-Create Setup"

# Fix ownership of credential directories
for dir in /home/vscode/.config /home/vscode/.claude /home/vscode/.codex; do
    if [ -d "$dir" ]; then
        sudo chown -R vscode:vscode "$dir"
    fi
done

echo "DevContainer Ready!"
```

---

## Testing Services

The devcontainer includes a test suite to verify all services are working:

```bash
# Test all running services
.devcontainer/tests/run-all-tests.sh --all

# Test specific services
.devcontainer/tests/run-all-tests.sh postgres minio

# List available tests
.devcontainer/tests/run-all-tests.sh --list
```

---

## Agent Verification Workflow

**Critical:** After generating devcontainer files, agents should verify the setup works before handing off to users. This section provides a complete CLI-based testing workflow.

### Prerequisites

Install DevContainer CLI on the host:
```bash
npm install -g @devcontainers/cli
devcontainer --version
```

### End-to-End Test Flow

#### Step 1: Pre-Flight Checks

```bash
# Verify Docker is running
docker info > /dev/null 2>&1 || { echo "Docker not running"; exit 1; }

# Verify workspace has devcontainer config
[ -f ".devcontainer/devcontainer.json" ] || { echo "Not a devcontainer workspace"; exit 1; }
```

#### Step 2: Provision Environment (REQUIRED FIRST)

Always run `devcontainer up` first. This command:
- Builds/starts the app container
- Starts services defined in `COMPOSE_PROFILES`
- Runs post-create setup scripts
- Mounts the workspace properly

```bash
devcontainer up --workspace-folder .
```

> **Important:** This command is idempotent—if containers are running, it attaches. If down, it starts them.

#### Step 3: Start Additional Services

If `COMPOSE_PROFILES` doesn't include all services (default is `app,postgres,minio`), start the rest:

```bash
# Start services not in COMPOSE_PROFILES
docker compose -f .devcontainer/docker-compose.yml \
  --profile mysql \
  --profile mongo \
  --profile valkey \
  --profile kafka \
  --profile opensearch \
  up -d

# Wait for health checks (Kafka and OpenSearch need 30-60s)
sleep 30

# Verify all services are healthy
docker compose -f .devcontainer/docker-compose.yml ps
```

**Alternative:** Modify `COMPOSE_PROFILES` to include all services upfront:
```json
"COMPOSE_PROFILES": "app,postgres,minio,mysql,mongo,valkey,kafka,opensearch"
```

#### Step 4: Execute Tests Inside Container

Get the container name and run tests via `docker exec`:

```bash
# Get app container name
APP_CONTAINER=$(docker compose -f .devcontainer/docker-compose.yml ps app --format "{{.Name}}" | head -1)

# Run individual test scripts (recommended approach)
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-postgres.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-rustfs.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-mysql.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-mongo.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-valkey.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-kafka.sh
docker exec -w /workspaces/app $APP_CONTAINER bash .devcontainer/tests/test-opensearch.sh
```

> **Why `docker exec` instead of `devcontainer exec`?** The `run-all-tests.sh` script uses `docker compose` internally to detect running services. If Docker isn't in the container's PATH (common with Docker-out-of-Docker), this fails. Running individual test scripts directly bypasses this issue.

#### Step 5: Validate Results

Expected: **77 tests passed, 0 failed** (when all 7 services are running)

```bash
# Check test report if generated
cat .devcontainer/tests/TEST-REPORT.md
```

#### Step 6: Graceful Shutdown

Free up ports and memory:

```bash
# Stop all containers
docker compose -f .devcontainer/docker-compose.yml stop

# Verify containers stopped
docker compose -f .devcontainer/docker-compose.yml ps
# Should show no running containers
```

### Automated Test Script

Use `agent-test.sh` to automate the entire workflow:

```bash
.devcontainer/tests/agent-test.sh
```

This script:
1. Runs pre-flight checks
2. Provisions the devcontainer
3. Starts all services
4. Executes all test scripts
5. Reports results with colored output
6. Shuts down containers
7. Returns exit code 0 (success) or 1 (failure)

### Agent Self-Correction Rules

| Symptom | Action |
|---------|--------|
| "Port already allocated" | Stop conflicting local service (postgres, mysql, etc.) on host |
| "Command not found: psql" | Agent is running on host, not in container. Use `docker exec` |
| "Container timed out" | Check logs: `docker compose -f .devcontainer/docker-compose.yml logs <service>` |
| "Dev container not found" | Restart: `devcontainer up --workspace-folder .` |
| "Service not running" | Start it: `docker compose -f .devcontainer/docker-compose.yml --profile <service> up -d` |
| "docker: command not found" (in container) | Use `docker exec` from host instead of `devcontainer exec` |
| "Failed to install awscli" | Test script auto-falls back to AWS CLI v2 standalone installer |
| Kafka/OpenSearch unhealthy | Wait longer (60-90s) or check memory limits |

### Key Testing Insights

1. **`devcontainer up` is always first** — Never run `docker compose up` directly without it
2. **Service profiles** — Only services in `COMPOSE_PROFILES` start with `devcontainer up`
3. **Health checks matter** — Kafka needs 60s+, OpenSearch needs 30-60s
4. **Test from inside container** — Network names (postgres, minio) only resolve inside the container
5. **AWS CLI fallback** — RustFS test tries uv → pip → standalone installer

---

## Troubleshooting

### Port Already in Use

**Symptom:** Container fails to start with port conflict.

**Solution:** The configuration uses dynamic ports (`127.0.0.1:0:PORT`), so this shouldn't happen. If using fixed ports, switch to dynamic:

```yaml
ports:
  - "127.0.0.1:0:5432"  # Dynamic - Docker assigns free port
  # NOT: "5432:5432"    # Fixed - will conflict
```

### Finding Assigned Ports

```bash
# From inside the container
docker compose -f .devcontainer/docker-compose.yml ps

# Get specific service port
docker compose -f .devcontainer/docker-compose.yml port postgres 5432
```

**Inside the container, always use service names:**
- `postgres:5432` (not `localhost:5432`)
- `minio:9000`
- `kafka:9092`

### Git Commands Fail

**Symptom:** `fatal: not a git repository`

**Cause:** Git worktree common directory not mounted.

**Fix:** Ensure `init.sh` ran:
```bash
cat .devcontainer/.env | grep GIT_COMMON_DIR
```

If missing, rebuild container: Cmd/Ctrl+Shift+P → "Dev Containers: Rebuild Container"

### Kafka Takes Forever to Start

**Expected:** Kafka in KRaft mode takes 60+ seconds to initialize.

**Fix:** The healthcheck has `start_period: 60s`. Wait for it, or check:
```bash
docker compose -f .devcontainer/docker-compose.yml logs kafka
```

### OpenSearch Out of Memory

**Symptom:** OpenSearch container exits or becomes unresponsive.

**Cause:** Default JVM heap is 512MB, may need more for large indices.

**Fix:** Increase heap in docker-compose.yml:
```yaml
environment:
  - "OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g"
```

### Volume Permissions

**Symptom:** Permission denied when writing to mounted directories.

**Fix:** Run `post-create.sh` manually or rebuild:
```bash
sudo chown -R vscode:vscode /home/vscode
```

---

## Limitations

This skill does **not** handle:

- **Cloud deployment** → use **deployment** skill
- **Production app specs** → use **designer** skill
- **Hot reload in cloud** → use **hot-reload** skill
- **Database migrations** — generate empty databases only; bring your own migration tool
- **DigitalOcean Functions** — not containerizable for local dev
- **App Platform build process** — local dev uses source directly, not buildpacks
- **SSL/TLS** — local dev uses plain HTTP; production handles SSL automatically

---

## Artifact Summary

All artifacts are sourced from **`${DEVCONTAINER_REPO_URL}`**

| Artifact | Path | Description |
|----------|------|-------------|
| DevContainer config | `.devcontainer/devcontainer.json` | IDE/container setup |
| Docker Compose | `.devcontainer/docker-compose.yml` | All backing services |
| Git worktree support | `.devcontainer/init.sh` | Run before container starts |
| Post-create setup | `.devcontainer/post-create.sh` | Run after container created |
| E2E validation | `.devcontainer/tests/agent-test.sh` | Automated agent verification |
| Test runner | `.devcontainer/tests/run-all-tests.sh` | Master test script |
| Service tests | `.devcontainer/tests/test-*.sh` | Individual service tests |
| Test helpers | `.devcontainer/tests/common.sh` | Shared test functions |

### Environment Template

After copying `.devcontainer/`, create `env-devcontainer.example` in the project root with connection strings (see Environment Variables section).

---

## Next Steps

After setting up local development:

1. **Design production architecture** → use **designer** skill to create `app-spec.yaml`
2. **Set up CI/CD** → use **deployment** skill to create GitHub Actions workflow
3. **Test in cloud** → use **hot-reload** skill for faster cloud iteration

---

## Reference

- [VS Code Dev Containers](https://code.visualstudio.com/docs/devcontainers/containers)
- [Docker Compose](https://docs.docker.com/compose/)
- [App Platform Environment Variables](https://docs.digitalocean.com/products/app-platform/how-to/use-environment-variables/)
- [Reference Implementation](${DEVCONTAINER_REPO_URL})
